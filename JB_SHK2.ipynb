{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"JB_SHK2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1HrK75kYBr7kzO7IR0uZDawnmec5JX1iv","authorship_tag":"ABX9TyO7lQgACEio57ARV6Xw1/92"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Описание\n","В настоящее время количество выходящих в течение года научных публикаций велико и растёт экспоненциально во многих областях, в связи с чем открывается простор для создания автоматических инструментов, помогающих в поиске и обработке информации. В частности, веб-сервис [PubTrends](https://pubtrends.net/) позволяет взглянуть на множество статей, соответствующих поисковому запросу, как на единое целое, выделяя подразделы научных направлений, динамику их развития и тем самым структурируя результаты выдачи.\n","В рамках текущего проекта предлагается добавить в список возможностей сервиса извлечение численных показателей, а также визуализацию результатов и возможность фильтрации статей на основе извлеченных значений. Такая функциональность может быть полезна, например, в биомедицинской литературе для поиска статей с большим количеством испытуемых, а в технической - для получения представления о получаемых значений целевой метрики в рамках различных задач.\n","Для извлечения численных показателей из текста уже существуют инструменты, такие как [grobid-quantities](https://grobid-quantities.readthedocs.io/en/latest/) или [marve](https://arxiv.org/pdf/1710.04312.pdf). Фокус этой практики будет обращен именно на агрегацию информации из множества статей и использование этой информации для фильтрации статей. Первоначально разработка будет вестись в рамках Jupyter Notebook, при успешном выполнении задач планируется интеграция модуля в существующий веб-сервис."],"metadata":{"id":"ijKuT5CnoOaY"}},{"cell_type":"markdown","source":["*Почему вам интересен этот проект?*\n","\n","В моей научной деятельности, которая завязана на эксперименте и моделировании, численные величины часто определяют суть работы. Например, эксперименты при разных температурах (от комнатной до гелиевой) могут кардинально отличаться по используемым методам и применяемым моделям. Такая информация не всегда явно выделяется словесным описанием, и было бы удобно иметь инструмент для её извлечения и классификации работ по некоторым численным показателям. Вопросы к цифрам в публикациях коллег по области возникают достаточно часто в моей работе, поэтому мне было бы крайне интересно принять участие в таком проекте, довести его до реализации и в перспективе пользоваться таким инструментом.\n"],"metadata":{"id":"YDoFSoL8osNK"}},{"cell_type":"markdown","source":["#Задача 1\n","Задачи\n","\n","Установить [grobid-quantities](https://grobid-quantities.readthedocs.io/en/latest/)\n","\n","Скачать CSV файл с информацией о статьях по [ссылке](https://drive.google.com/file/d/1d3NJbq7EInZYl8Q5Pb7YfAwQUVxZ9FdE/view?usp=sharing).\n","Загрузить данные из CSV. Файл содержит две колонки: PMID (идентификатор статьи в базе Pubmed) и abstract (текст аннотации).\n","\n","Используя REST API запущенного локально сервиса grobid-quantities, извлечь все численные показатели из аннотаций статей. В рамках этого задания достаточно поддержать только тип значений value (см. [документацию](https://grobid-quantities.readthedocs.io/en/latest/restAPI.html#response-description) grobid-quantities).\n","\n","Построить гистограмму извлеченных значений, относящихся к слову ‘accuracy’ в текстах аннотаций."],"metadata":{"id":"_WtY2fzUo0pI"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/CSC/2022_spring_internship/JB_SHK2\n","!pip install -r requirements.txt "],"metadata":{"id":"swnPkX7Vsmcv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZM64IS6SoENb"},"outputs":[],"source":["import grobid_quantities.quantities \n","import pandas as pd\n","import numpy as np\n"]},{"cell_type":"code","source":["df = pd.read_csv('2022_JBR_Spring_Internship_Test_Data.csv')\n"],"metadata":{"id":"DO32R2EnNhLc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.abstract[10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":174},"id":"Poa70ucANy0V","executionInfo":{"status":"ok","timestamp":1645160674554,"user_tz":-420,"elapsed":420,"user":{"displayName":"Ivan Timofeev","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774109340500507461"}},"outputId":"9f56a2b3-819c-44da-933f-99a188758d7d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Highly sophisticated control based on a brain-computer interface (BCI) requires decoding kinematic information from brain signals. The forearm is a region of the upper limb that is often used in everyday life, but intuitive movements within the same limb have rarely been investigated in previous BCI studies. In this study, we focused on various forearm movement decoding from electroencephalography (EEG) signals using a small number of samples. Ten healthy participants took part in an experiment and performed motor execution (ME) and motor imagery (MI) of the intuitive movement tasks (Dataset I). We propose a convolutional neural network using a channel-wise variational autoencoder (CVNet) based on inter-task transfer learning. We approached that training the reconstructed ME-EEG signals together will also achieve more sufficient classification performance with only a small amount of MI-EEG signals. The proposed CVNet was validated on our own Dataset I and a public dataset, BNCI Horizon 2020 (Dataset II). The classification accuracies of various movements are confirmed to be 0.83 (±0.04) and 0.69 (±0.04) for Dataset I and II, respectively. The results show that the proposed method exhibits performance increases of approximately 0.09~0.27 and 0.08~0.24 compared with the conventional models for Dataset I and II, respectively. The outcomes suggest that the training model for decoding imagined movements can be performed using data from ME and a small number of data samples from MI. Hence, it is presented the feasibility of BCI learning strategies that can sufficiently learn deep learning with a few amount of calibration dataset and time only, with stable performance.'"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":[""],"metadata":{"id":"fVH4Qnf3o83R"}}]}